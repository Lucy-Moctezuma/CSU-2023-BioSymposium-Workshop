{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucy-Moctezuma/ML-Tutorial-for-Antibiotic-Resistance-Predictions-for-E.-Coli/blob/main/5)_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(**Note:**\n",
        "Click on the button that reads *“Open in Colab”* to open this code in Google Colab. Once open in Google Colab, you can make a copy of the notebook in your personal drive and run the code by clicking a little triangle/arrow to the left of each code block.)"
      ],
      "metadata": {
        "id": "ZOW5vq0h3qQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Network**\n",
        "\n",
        "## ***Objectives for this Notebook***\n",
        "- Introducing the importance of feature scaling and basic concepts behind Neural Networks used in the context of tabular data.\n",
        "- Create functions to implement Neural Networks into Moragadivand's dataset.\n",
        "\n",
        "**Neural Networks**  is a method within Machine Learning (ML) in which the computer learns to accomplish a task through trial and error by analyzing training samples. Neural networks are loosely inspired by how biological neurons are connected and signal each other. It's important to know that there are many kinds of neural networks that can be used for different kinds of data (images, sounds, etc) and there are specific names for different Neural network architectures (Convolutional Neural Networks, Recurrent Neural Networks, etc.). We will however focus only with basic Neural Network for tabular data (i.e. dataframes).\n",
        "\n",
        "### **Parts of a Neural Network**\n",
        "\n",
        "All neural networks despite of their function and kind of data they deal with have in essence these following parts.\n",
        "\n",
        "![neuralnet.png](https://drive.google.com/uc?export=view&id=1df7Dq1LS9QTFOdLuvOWb1Et6IiMIq4FK)\n",
        "\n",
        "**1) Input layer:** is the layer that we use to feed our initial data. These can be data tables, text, images, etc. In our case we would be working with a data table, and this layer will contain the same amount of nodes as there are feature columns in our dataset.\n",
        "\n",
        "**2) Hidden layers:** are the ones that will further process the information they receive from the input layer. In the example above we have 2 hidden layers but the amount of layers can vary depending on the task.\n",
        "\n",
        "**3) Output layer:** is the final layer where we get our predictions, because we are dealing with classification of just 2 classes we will have 2 nodes in this layer.\n",
        "\n",
        "**4) Nodes:** are the the components of each layer and it represents a center where computation and mathematical equations determine what information is passed to the next layer. Nodes are connected to the following layers differently.\n",
        "\n",
        "**5) Weights:** are values that are meant to show the strength of the relationship between each node. The general idea is that a neural network starts with a random set of weights and then during training, the weights get updated in a trial and error fashion until it finds the best combination of weights that will yield the highest performing model.\n",
        "**Notice that in the image above, every black arrow has its own weight**\n"
      ],
      "metadata": {
        "id": "4s_KUXfGSthq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1) Importing Packages needed**\n",
        "For Neural Networks we will introduce some new python packages: **Keras** and **Tensorflow**. Both of these are widely used within the Python community to construct Neural Networks. In addition we will install the package **Scikeras**, which is a wrapper that let us hyperparametertune our NN model using GridSearch.\n",
        "\n",
        "**NOTE:** When running the code below do not worry if you encounter an error using pip install, this is just due to package compatibilities. But scikeras resolves this automatically. You can run it again and you will see that the installation is done correctly."
      ],
      "metadata": {
        "id": "fnpxHzYUUJ_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please install the following package first\n",
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "7F4a-iNzOQfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDa820s0JSoJ"
      },
      "outputs": [],
      "source": [
        "# Data manipulation imports for ML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Import packages for Neural Networks model and hyperparameter tuning\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedGroupKFold, KFold\n",
        "import keras as keras\n",
        "import tensorflow as tf\n",
        "import scikeras\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Imports for model evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import f1_score, make_scorer, accuracy_score, recall_score, precision_score\n",
        "import warnings\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
        "\n",
        "\n",
        "# Imports for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.utils import plot_model\n",
        "\n",
        "print(\"Tensorflow version:\",tf.__version__)\n",
        "print(\"Keras version:\",keras.__version__)\n",
        "print(\"Scikeras version:\",scikeras.__version__)\n",
        "\n",
        "# Imports for file management\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because this tutorial uses a combination of 3 different packages for creating and evaluating the models, we have to make sure that the versions are correct. In this case make sure you have the following versions:\n",
        "- Tensorflow version: 2.15\n",
        "- Keras version: 3.3.3\n",
        "- Scikeras version: 0.13.0"
      ],
      "metadata": {
        "id": "r1fqMzsf4m96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SEED SETTING**\n",
        "\n",
        "There is a lot of randomness that contribute to Neural Networks results. Nevertheless, a good Neural Network Model should not depend on the seed but the data used and the architecture, given this, metrics should not be extremely affected by seed setting. Therefore this randomness is actually desired and not a problem.\n",
        "\n",
        "However, for the sake of this learning tutorial and for reproducibility of these results we will be fixing **seed_value: 42** for all the background computations. Below we list the different sources of randomness:\n",
        "\n",
        "- Within Environment\n",
        "- Within Python language\n",
        "- Within specific packages (numpy, tensorflow)\n",
        "- When choosing splits for training and testing data\n",
        "- Within Learning Algorythm:\n",
        "  - Neural network sets random weights at the beggining of training\n",
        "  - Some special layers such as Dropout layers introduce randomness\n",
        "\n",
        "The code below will **seed_value: 42** globally for the environment, the **python** language and for 2 packages (**numpy and tensorflow**). We will also quickly indicate where we have set other seeds. Everytime a seed is set you will see `seed_value` within the code of this notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "RS3oD-bjJFY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a seed value\n",
        "seed_value= 42\n",
        "\n",
        "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
        "tf.random.set_seed(seed_value)"
      ],
      "metadata": {
        "id": "sd-BLHih2XpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) Loading CSV file and creating dataframes for each antibiotic**\n",
        "\n",
        "As in all previous ML model Notebooks, We will load our original dataframe, which contains all antibiotic drug labels and all features (GY) and then we will be creating a dataframe for each antibiotic using different functions."
      ],
      "metadata": {
        "id": "1MTk8vozVJqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **a) Loading CSV created from previous notebook**\n",
        "\n",
        "**NOTE:** Code below is the same as in previous notebook"
      ],
      "metadata": {
        "id": "QNuEJfKcVSLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads csv file as a dataframe\n",
        "filepath = '/content/drive/My Drive/EColi_ML_CSV_files/'\n",
        "\n",
        "# reads csv file as a dataframe\n",
        "All_Drugs_df = pd.read_csv(filepath+\"EColi_Merged_df.csv\", na_values=\"NaN\")\n",
        "All_Drugs_df.head()"
      ],
      "metadata": {
        "id": "psqfFp_yVsmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **b) Changing \"R\" to 0 and \"S\" to 1  for Neural Network Model**\n",
        "Neural Networks work using numeric values, therefore we will be converting all our target labels into floats. The last line of code shows the recoded version of all the labels for the antibiotic drugs."
      ],
      "metadata": {
        "id": "Gnvbqq1Eduja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a list of antibiotic names\n",
        "drug_list = All_Drugs_df.iloc[:,3:15].columns\n",
        "\n",
        "# converts all S values into 1 for each antibiotic\n",
        "for drug in drug_list:\n",
        "  All_Drugs_df.loc[All_Drugs_df[drug] == \"S\", drug] = 1.0\n",
        "\n",
        "# converts all R values into 0 for each antibiotic\n",
        "for drug in drug_list:\n",
        "  All_Drugs_df.loc[All_Drugs_df[drug] == \"R\", drug] = 0.0\n",
        "\n",
        "# Checking at how S and R classes were recoded\n",
        "All_Drugs_df.head()"
      ],
      "metadata": {
        "id": "lLeCU30hD0Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3) Separating each Drug Dataframe into 4 sections : Training (features and labels) and Testing (features and labels)**\n",
        "\n",
        "**NOTE:** Code below is the same as in previous notebook"
      ],
      "metadata": {
        "id": "NMKzeaqPojso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a) Creating Testing and Training datasets for each antibiotic drug**\n",
        "\n",
        " *Seed value was used in the train_test_split() function, to split the data consistentently, that is, the observations chosen to be part of the training chunk will be consistent regardless of how many times the code is ran.*\n",
        "\n"
      ],
      "metadata": {
        "id": "B2BblFQkce6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating each dataframe into Labels and Features for training and testing data.\n",
        "# Our function uses the handy train_test_split() function.\n",
        "\n",
        "def Split_train_test(drug):\n",
        "  #here we make a list of the columns we want to keep: the column for the isolate, the column for the drug we are interested in and all features (starting from column 13).\n",
        "  df_list = [All_Drugs_df[[\"MLST\",\"Isolate\",drug,\"Year\"]], All_Drugs_df.iloc[:,15:]]\n",
        "\n",
        "  #here we create a data frame with just the columns we wanted to keep.\n",
        "  Drug_df = pd.concat(df_list, axis=1)\n",
        "\n",
        "  #here we drop all rows with missing data\n",
        "  Drug_df = Drug_df.dropna()\n",
        "\n",
        "  # Creating a dictionary to store each antibiotic datasets\n",
        "  Train_test_dic = {}\n",
        "\n",
        "  # Defining the label columns\n",
        "  labels = Drug_df[drug]\n",
        "\n",
        "  # Defining features columns\n",
        "  features = Drug_df.drop(columns=[drug])\n",
        "\n",
        "  # Separating training (features and labels) and testing (features and labels) datasets\n",
        "  features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.20, random_state=seed_value, stratify=labels)\n",
        "\n",
        "  # storing each data chunk in a dictionary\n",
        "  Train_test_dic['labels_train'] = labels_train\n",
        "  Train_test_dic['features_train'] = features_train\n",
        "  Train_test_dic['labels_test'] = labels_test\n",
        "  Train_test_dic['features_test'] = features_test\n",
        "\n",
        "  return Train_test_dic"
      ],
      "metadata": {
        "id": "iP4HEW4qBO7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the function Split_train_test() for AMC example\n",
        "AMX_Train_test_dic = Split_train_test(\"AMX\")\n",
        "\n",
        "# checking the shape of each dataframe or series stored in the dictionary created for drug AMC\n",
        "print(\"AMX\")\n",
        "for k, df in AMX_Train_test_dic.items():\n",
        "  print(k, df.shape)\n",
        "  # counting how many of the labels have susceptible versus resistant ones\n",
        "  if k.startswith(\"labels\"):\n",
        "    print(df.value_counts())"
      ],
      "metadata": {
        "id": "43qPwvrrqCaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that our target values have been recoded. **0.0 is Resistance (R)** and **1.0 is Susceptible (S)**. And in our implementation we used the antibiotic AMX. The total number of training observations is 875."
      ],
      "metadata": {
        "id": "imprnOtpedzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4) Creating different combination of features before training**\n",
        "\n",
        "**NOTE:** Similar Code to prior notebooks\n"
      ],
      "metadata": {
        "id": "2IyqN506dQn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making a list of combinations of data sources we would like to test in our ML models\n",
        "combo_list = ['Y', 'G', 'GY']\n",
        "\n",
        "# making a function that creates different feature combinations of the predictor features\n",
        "def combo_feat(features_df, drug, combo):\n",
        "\n",
        "  # Isolating Year as a feature and\n",
        "  year_filter = [col for col in features_df if col.startswith(\"Year\")]\n",
        "  year_feat = features_df[year_filter]\n",
        "\n",
        "  # creating Gene precence column filters for features_df\n",
        "  gene_presc_filter = [col for col in features_df.columns if col not in year_filter and col != \"Isolate\"]\n",
        "  gene_presc_feat = features_df[gene_presc_filter]\n",
        "\n",
        "  if combo == 'Y':\n",
        "    df_list = [features_df[['MLST','Isolate']], year_feat]\n",
        "    Y_feat_df_t = pd.concat(df_list, axis=1)\n",
        "    Y_feat_df_t = Y_feat_df_t.drop(columns=['Isolate'])\n",
        "    return Y_feat_df_t\n",
        "\n",
        "  if combo == 'G':\n",
        "    df_list = [features_df['Isolate'], gene_presc_feat]\n",
        "    G_feat_df = pd.concat(df_list, axis=1)\n",
        "    G_feat_df = G_feat_df.drop(columns=['Isolate'])\n",
        "    return G_feat_df\n",
        "\n",
        "  if combo == 'GY':\n",
        "    df_list = [features_df['Isolate'], year_feat, gene_presc_feat]\n",
        "    GY_feat_df_t = pd.concat(df_list, axis=1)\n",
        "    GY_feat_df_t = GY_feat_df_t.drop(columns=['Isolate'])\n",
        "    return GY_feat_df_t"
      ],
      "metadata": {
        "id": "JmzbwQBxlylk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing combo_feat() function created for training data\n",
        "AMX_GY_train_df = combo_feat(AMX_Train_test_dic['features_train'],\"AMX\",\"GY\")\n",
        "\n",
        "# Now each feature combination has its own dataframe\n",
        "AMX_GY_train_df.head()"
      ],
      "metadata": {
        "id": "z6f4cke-qHxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Neural networks, we need to convert our dataframe to an array. Passing a dataframe would be lower the performance dramatically. Therefore we will actually convert our features later when we actually pass them into our NN model."
      ],
      "metadata": {
        "id": "IpEQIYwUYH9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the shape of the array we can see that it is the same as the dataframe\n",
        "AMX_GY_train_df.shape"
      ],
      "metadata": {
        "id": "bIh7NOl5Yvml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5) Creating Neural Network model and training it per feature combination**\n",
        "\n"
      ],
      "metadata": {
        "id": "ZVOKCEZNeHzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general structure of how a Neural network is created is fairly loose, because it depends on the kind of data we are fitting, how complex the pattern you are trying to capture, etc. This tutorial focuses on structured data specifically and we used the NN structure created by **\"Moradigavand\"**. Know that you can change these parameters and test what works as it is part of *hyperparameter tuning*, which will be dicussed further in part 6 of this notebook.  \n",
        "\n",
        "Shown below in the pseudo code to create a neural network in general, we will also briefly define some vocabulary used in our code and specify what choices were made for each hyperparameter:\n",
        "\n",
        "<font color=\"grey\">`Model.add(Layertype(#_output_weights, activation= 'specific function', input_shape=#_input_weights)`\n",
        "\n",
        "**A) For Neural Network *Architechture*:**\n",
        "\n",
        "- **Dense:** This is a kind of layer, where each node from a dense layer receives conexions from all the previous nodes, for this reason they are often called **\"fully connected\"**. For our NN:\n",
        "  - 1 input dense layer of neurons that output 200 weights.\n",
        "  - 1 intermediate dense layer of neurons that outputs 100 weights.\n",
        "\n",
        "- **Dropout:** This is a special type of layer with the sole function to block a percentage of weights that pass from one layer to the next. A Dropout rate assigns a percentage of randomly selected neurons in a layer to become inactive, meaning their contribution in the forward pass is not taken into account and therefore the weights in the backward pass towards these dropout neurons do not get updated. This is considered to be a **Regularization method**, meaning it is done so that our model doesn't follow the training data too closely and is able to generalize better for unseen data. For our NN:\n",
        "  - 1 dropout layer between input and hidden layer with 0.8 weights dropped.\n",
        "  - 1 dropout layer between hidden and output layer with 0.8 weights dropped.\n",
        "\n",
        "- **Activation function:** is a parameter we can pass for some types of layers, it is essentially a function that computes the output for a layer. For example, for Dense layers we have [\"Relu\"](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)), whereas for dropout layers we dont have one, as they don't need to compute an output, they just block outputs from the layer before from going to the next layer, by converting some of these to 0. For our NN:\n",
        "  - Activation function on input layer is \"relu\"\n",
        "  - Activation function on hidden layer is \"relu\"\n",
        "  - Activation function on output layer is \"softmax\"\n",
        "***\n",
        "\n",
        "**B) For Neural Network *Training behavior*:**\n",
        "\n",
        "The function created allows you to create the model (Network Architecture) and compile it (Training Behavior)\n",
        "\n",
        "<font color=\"grey\">`EarlyStopping(patience=# training epochs)`\n",
        "\n",
        "- **Early Stopping:** is a parameter that essentially stops the training based on the maximum number of epochs accepted before stopping the training if no improvement is seen. For our NN training behavior:\n",
        "  - We set a patience of 5 epochs.\n",
        "\n",
        "<font color=\"grey\">`Model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=lr) ,loss= 'binary_crossentropy', metrics=['accuracy','recall','precision'])`\n",
        "\n",
        "- **Optimizer**: is the algorithm used to adjust the weights based on training rates. For our NN training behavior:\n",
        "  - Our optimzer was \"Adam\"\n",
        "\n",
        "- **Learning rate**: is a value between 0 and 1, that determines basically how fast our model will try to learn. The higher the learning rate, the less number of epochs (training cycles) is required. This is the most important parameter to tune in a Neural Network. Too large and it will converge too quickly and provide a suboptimal result, too small and it will get stuck.For our NN training behavior:\n",
        "  - Our base learning rate is 0.001\n",
        "\n",
        "- **Loss function**: there are many loss functions we can use depending on the type of data and task. A loss function is essentially a method used to evaluate how well our algorithm models our training data. Our objective is to minimize it since its essentially our errors. For our NN training behavior:    \n",
        " - *binary_crossentropy* (a mathematical function that measures the difference between predicted probabilities and actual labels in classification task with only 2 classes)\n",
        "\n",
        "- **Metrics**: this is just a measurement we can look at in order to judge the performance of the model while training, and as our loss function is being optimized. In our case we use actually a Weighted Metrics, since we have class imbalance. For our NN training behavior:\n",
        "  -  We chose to use Accuracy, precision and recall. For the last 2 metrics, they are the average of the 2 classes (R & S).\n",
        "\n",
        "The function we are creating allows us to just stop here and just create our model or we can actually also control how we feed the data when training as well.\n",
        "\n",
        "<font color=\"grey\">`Model.fit(features, to_categorical(labels), validation_split = percent of training data used for validation, callbacks= [early_stopping_monitor],epochs=# of training cycles, batch_size= # observations fed at a time))`\n",
        "\n",
        "A Neural Network, is trained in 2 general stages:\n",
        "\n",
        "**1) Feedforward**: First the observations start on the input layer go through all the hidden layers and then it produces an initial prediction in the output layer.\n",
        "\n",
        "**2) Backpropagation**: An error is calculated between our actual training labels and the output we got from the Feedforward process. It then adjusts the weights from output layer back to input layer in order to minimize the errors.\n",
        "***\n",
        "\n",
        "**Epoch:** Is one cycle of training where the entire dataset goes through a Feedforward process and a Backpropagation one.\n",
        "  - We have set a total of 10 epochs.\n",
        "\n",
        "**Batch:** Because feeding the entire dataset might be computationally expensive, it is a common practice to feed our neural network data in batches.\n",
        "  - We have chosen a batch size of 128.\n",
        "\n",
        "**Validation Data:** Is a chunk of the training data that is reserved to check if our model is generalizing well to all the training data. This is different from the testing data, because it is being used during model training.\n",
        "  - We set validation to be 20% or 0.02\n",
        "\n",
        "**NOTES:** Seed_values were set here for the initial weights prior to training and for every Dropout layer in the Neural Network"
      ],
      "metadata": {
        "id": "IvN6NM_jxsV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating Neural Network model function\n",
        "def run_NN(feat_train_df, lab_train, drug, combo,fit = True, view_training = True, view_epoch=0, lr=0.0001, rate=0.8):\n",
        "  print(drug +\" Training combo: \"+ combo)\n",
        "\n",
        "  # Reweighting classes due to imbalanced dataset\n",
        "  class_labels = np.unique(lab_train)\n",
        "  reweight = compute_class_weight(class_weight='balanced', classes=class_labels, y=lab_train)\n",
        "\n",
        "  # Converting features into arrays and rescaling them\n",
        "  feat = feat_train_df.drop(columns=['MLST'])\n",
        "  scaler = MinMaxScaler()\n",
        "  feat_array_t = scaler.fit_transform(feat)\n",
        "  # Choose the type of Neural Network you want create\n",
        "  NN = Sequential()\n",
        "  # Adding the first input layer.\n",
        "  NN.add(Dense(200,activation='relu'))\n",
        "  # Adding the dropout layer for the first layer.\n",
        "  NN.add(Dropout(rate, seed=seed_value))\n",
        "  # Create hidden layers\n",
        "  NN.add(Dense(100 ,activation='relu'))\n",
        "  # For each of the hidden layers also create dropout\n",
        "  NN.add(Dropout(rate, seed=seed_value))\n",
        "  # Create the output layer that consist only on 1 node predicting probabilities with a threshold of 0.5\n",
        "  NN.add(Dense(1, activation = 'sigmoid', kernel_initializer=keras.initializers.glorot_uniform(seed=seed_value)))\n",
        "  # Additional parameters for training (Early stopping)\n",
        "  early_stopping_monitor= EarlyStopping(patience=10)\n",
        "  # Compiling model created\n",
        "  NN.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=lr) ,loss= 'binary_crossentropy', weighted_metrics=['accuracy'])\n",
        "  if fit == True:\n",
        "    # Training with the neural network created\n",
        "    NN_history = NN.fit(x=feat_array_t, y=lab_train.to_numpy(dtype=float) , validation_split=0.2, callbacks= [early_stopping_monitor], epochs=10, batch_size=128, class_weight=dict(enumerate(reweight)), verbose=view_epoch)\n",
        "    # visualizing each training\n",
        "    if view_training == True:\n",
        "      fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "      fig.suptitle('Training History')\n",
        "      print(NN_history.history.keys())\n",
        "      ax1.plot(NN_history.history['accuracy'])\n",
        "      ax1.plot(NN_history.history['val_accuracy'])\n",
        "      ax1.set_title('model accuracy')\n",
        "      ax1.set(ylabel='accuracy', xlabel='epochs')\n",
        "\n",
        "      ax2.plot(NN_history.history['loss'])\n",
        "      ax2.plot(NN_history.history['val_loss'])\n",
        "      ax2.set_title('model loss')\n",
        "      ax2.set(ylabel='loss', xlabel='epochs')\n",
        "      ax2.legend(['train', 'validation'], loc='best')\n",
        "      fig.tight_layout()\n",
        "      filepath='/content/drive/My Drive/EColi_ML_Plots/'\n",
        "      plt.savefig(filepath + 'NN_' + drug + '_' + combo + '_' + 'training_history.jpg',dpi=400, bbox_inches=\"tight\")\n",
        "    return NN\n",
        "  else:\n",
        "    return NN"
      ],
      "metadata": {
        "id": "QbEP2WYkWPxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The year has been rescaled using MaxMinScaler(), which rescales the year variable into the range from 0 to 1, in order to ease the model's learning. Rescaling is not always needed for all models but it is important for Neural Networks as it makes it easier to converge. There are other rescaling techniques you can read a short summary about them [here](https://www.kaggle.com/discussions/general/138076).\n",
        "\n",
        "**C) Applying our function to an example:**\n",
        "\n",
        "The total number of observations is 875 for AMX, and our batch size is 128. Therefore, in one epoch we will have 700 observations to fit as 20 percent is used as validation, so about 6.83 batches per epoch, which rounding up is 6 batches per epoch. Below we will implement our function for the antibiotic AMX and using only the features (G and Y)."
      ],
      "metadata": {
        "id": "OjQpX3cytgnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing run_NN() for specific drug feature combination dataframe\n",
        "NN_AMX_GY_model = run_NN(AMX_GY_train_df, AMX_Train_test_dic['labels_train'], drug=\"AMX\",combo=\"GY\", view_epoch=1)"
      ],
      "metadata": {
        "id": "kJgB0ELDqLVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In the graph above we can see that training and validation data have an upwards direction, meaning that we can see that accuracies for both training and validation are going up, meaning there is learning happening.\n",
        "- We notice that the **training set** has a lower overall accuracy and a higher loss than the **validation set**, this is not usually the case, we would normally observed the reversed pattern. Because the validation is supposed to simulate unseen data it should have lower accuracies and higher loss, but because **Dropout layer** is implemented, regularization happens and this generalizability makes the validation metrics better. You can test this by lowering the dropout rates in a new session of this notebook, in doing so the lines will beggin to overlap and we will start to see more of a reversed pattern. The current dropout rate is at 0.8. Try changing the drop out rate to 0.2 to see what happens.\n",
        "\n",
        "Below we can plot the model layers:"
      ],
      "metadata": {
        "id": "q3SAcPzlM5gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the schematics of our model\n",
        "plot_model(NN_AMX_GY_model, to_file='/content/drive/MyDrive/EColi_ML_Plots/NN_AMX_GY_model_Architechture.jpg', show_shapes=True, show_layer_activations=True, rankdir='LR')"
      ],
      "metadata": {
        "id": "HRqUdyhfNGcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see in the figure that the Input layers input contains 17199 nodes, this is because each node pertains to one feature. Remember that this model was trained with only G and Y dataset features. Our input layer nodes will change depending on out training data.\n",
        "\n",
        "For each layer we can see the following information displayed:\n",
        "- The name of the layer (example: dense)\n",
        "- The type of neurons the layer contains (example: Dense, Dropout)\n",
        "- The activation function the layer uses (example: softmax, relu)\n",
        "- The amount of connections for the nodes it receives (input) - The amount of connections leaving the node (output). For dropout layers, we see that input and output shape are the same. However, when a weight gets filtered here, the amount passed is 0. Also, which neurons' weights become 0 changes every cycle of training, which is why everytime we run the code it will give you slightly different results.\n",
        "\n",
        "Below in the model summary we can see that our model is quite large as it has more than 3 million parameters to train. Know that with that many parameters, the memory consumption will be higher."
      ],
      "metadata": {
        "id": "QgSQCNDH_KlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at model summary for more details\n",
        "NN_AMX_GY_model.summary()"
      ],
      "metadata": {
        "id": "VM9yPJriZQPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6) Making predictions from Neural Network model**\n",
        "\n",
        "After training our Neural network we are now ready to make predictions."
      ],
      "metadata": {
        "id": "1px3jn-Djn77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function using the model created and trained and the feature combinations from testing data\n",
        "def predict(NN_combo_Model, features_test):\n",
        "  feat = features_test.drop(columns=['MLST'])\n",
        "  scaler = MinMaxScaler()\n",
        "  feat_t = scaler.fit_transform(feat)\n",
        "  labels_pred = NN_combo_Model.predict(feat_t)\n",
        "  labels_pred = np.where(labels_pred < 0.5, 0, 1).reshape((len(labels_pred),))\n",
        "  return labels_pred"
      ],
      "metadata": {
        "id": "_3Cga_BTQCuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now use our **combo_feat()** function to choose the appropiate data feature combination for Testing. In the example below, we use the combination of features G and Y. We can also see the MLST column, but we will be ignoring it as it will not be used as a predictive feature."
      ],
      "metadata": {
        "id": "HwNlTWVIHJ__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing combo_feat() function created for testing data\n",
        "AMX_GY_test_df = combo_feat(AMX_Train_test_dic['features_test'],\"AMX\",\"GY\")\n",
        "AMX_GY_test_df.head()"
      ],
      "metadata": {
        "id": "cbzJt4FaqTIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we will implement our **predict()** function and checkout our predictions!\n",
        "\n",
        "**Resistant (R=0)** and **Susceptible (S=1)**. We see below that our model has predicted mostly Resistant isolates."
      ],
      "metadata": {
        "id": "I0Gg3ZGoHbTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of the predict() function using the feature combination \"GY\"\n",
        "AMX_GY_labels_pred = predict(NN_AMX_GY_model,AMX_GY_test_df)\n",
        "\n",
        "# observe how many predictions were made for each category \"R\"=0 and \"S\"=1\n",
        "print(\"Labels predicted: \")\n",
        "print(AMX_GY_labels_pred)"
      ],
      "metadata": {
        "id": "DIk2WxCzqTjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7) Evaluating our model using a confusion matrix and metrics**\n",
        "\n",
        "Similarly to the previous notebook, we will evaluate our Neural Network model by using a Confusion Matrix and respective metrics. Below is a quick review of these, remember that there is one Accuracy score, but Recall and Presicion should have as many sets as classes our model its trained to predict:\n",
        "\n",
        "|<font size=3>Metrics|<font size=3>General formula| <font size=3>Formula for 2 classes|\n",
        "|--|:-:|:-:\n",
        "|<font size=3>**Accuracy**|<font size=3>$\\frac{Correctly \\ classified}{All \\ Predicted}$|<font size=3>$\\frac{TP + TN}{TP + TN + FN + FP}$|\n",
        "|<font size=3>**R Recall:**|<font size=3>$\\frac{Correctly \\ classified \\ as \\ R}{All \\ Actual \\ R}$|<font size=3>$\\frac{TP}{TP + FN}$|\n",
        "|<font size=3>**R Precision:**|<font size=3>$\\frac{Correctly \\ classified \\ as \\ R}{All \\ Predicted \\ R}$|<font size=3>$\\frac{TP}{TP + FP}$|"
      ],
      "metadata": {
        "id": "5dox3JfFn5wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function that evaluates our model using our actual and predicted data\n",
        "def evaluate(NN_combo_model, features_test, labels_test, labels_pred, cf= True, show_results= True, tunned = False):\n",
        "\n",
        "  labels_test = np.asfarray(labels_test,float)\n",
        "  feat = features_test.drop(columns=['MLST'])\n",
        "  scaler = MinMaxScaler()\n",
        "  feat_t = scaler.fit_transform(feat)\n",
        "\n",
        "  labels = unique_labels(labels_test, labels_pred)\n",
        "  inp = precision_recall_fscore_support(labels_test, labels_pred, labels=labels, average=None)\n",
        "  report = np.asarray(inp).ravel().tolist()\n",
        "  report= pd.DataFrame(report, index = ['PRC_R','PRC_S','RCL_R','RCL_S','FSc_R','FSc_S','Sc_R','Sc_S'])\n",
        "  report = report.transpose()\n",
        "\n",
        "  if cf == True:\n",
        "    cm = confusion_matrix(labels_test, labels_pred, labels=labels, sample_weight=None)\n",
        "    labels= np.where(labels<1,\"R\",\"S\")\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "\n",
        "  if tunned == False:\n",
        "    score = NN_combo_model.evaluate(feat_t, labels_test)\n",
        "    if show_results == True:\n",
        "      print(\"Results\")\n",
        "      print('Accuracy:',score[1])\n",
        "      print('R recall:',report['RCL_R'][0])\n",
        "      print('S recall:',report['RCL_S'][0])\n",
        "      print('R precision:',report['PRC_R'][0])\n",
        "      print('S precision:',report['PRC_S'][0])\n",
        "    return [score[1], report['RCL_R'][0], report['RCL_S'][0], report['PRC_R'][0], report['PRC_S'][0]]\n",
        "  else:\n",
        "    score = NN_combo_model.score(feat_t, labels_test)\n",
        "    if show_results == True:\n",
        "      print(\"Results\")\n",
        "      print('Accuracy:',score)\n",
        "      print('R recall:',report['RCL_R'][0])\n",
        "      print('S recall:',report['RCL_S'][0])\n",
        "      print('R precision:',report['PRC_R'][0])\n",
        "      print('S precision:',report['PRC_S'][0])\n",
        "    return [score, report['RCL_R'][0], report['RCL_S'][0], report['PRC_R'][0], report['PRC_S'][0]]\n"
      ],
      "metadata": {
        "id": "YJJmoOq-o97t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing the evaluate() function\n",
        "Model_Report = evaluate(NN_AMX_GY_model,AMX_GY_test_df, AMX_Train_test_dic['labels_test'],AMX_GY_labels_pred)"
      ],
      "metadata": {
        "id": "wMjJYgGIqboe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8) (OPTIONAL) Hyperparameter Tuning and Crossvalidation for NN model**\n",
        "\n",
        "This section of the notebook is optional.\n",
        "Here we will carry out hyperparameter tuning using cross-validation to optimize the model's performance and ensure its robustness. We will also include code to use a blocked cross-validation design. These approaches are important to make good ML models. However, if you are just here to learn the basics, feel free to skip section 8."
      ],
      "metadata": {
        "id": "5bpSLia0H3gu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **a) Hyperparameter Tuning**\n",
        "\n",
        "Neural Networks can have an overwhelming amount of hyperparameters we could configure. Some of them have to do with the overall architecture of the network, that is the number of layers and neurons in each layer. For simplicity in this tutorial we will only tune one of the hyperparameters that do not change the architechture, only learning parameters (learning rate, batch sizes or dropout rate, etc). In this example we will tune only 2 hyperparameters : the learning rate and the batch sizes."
      ],
      "metadata": {
        "id": "avb-OMS9pdMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dictionary of parameters to tune.\n",
        "hparam = {\"lr\":[0.0001, 0.001],\n",
        "          \"rate\":[0.4, 0.8]}"
      ],
      "metadata": {
        "id": "XqnhODbzpjEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **b) Crossvalidation**\n",
        "\n"
      ],
      "metadata": {
        "id": "P5COr8BKMaBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating function to perform hyper parameter tuning of model\n",
        "def NN_hp_tune(param, feat_train_df, lab_train, drug, combo, v=3, lr=0.0001, rate=0.8, cv=4):\n",
        "  #Creating model and wrapping it under scikeras function for skit-lear compatibility\n",
        "  NNmodel = KerasClassifier(model=run_NN, verbose=0, lr=lr, rate=rate,\n",
        "                            feat_train_df = feat_train_df, lab_train=lab_train,\n",
        "                            drug=drug, combo=combo, view_training = False)\n",
        "  # performing the hyper parameter tuning using regular crossvalidation\n",
        "  scoring_dic = {'f1_macro':make_scorer(f1_score , average='macro')}\n",
        "\n",
        "  # Extracting features only from dataframe\n",
        "  feat = feat_train_df.drop(columns=['MLST'])\n",
        "  scaler = MinMaxScaler()\n",
        "  feat_t = scaler.fit_transform(feat)\n",
        "  # Chooosing crossvalidation scheme\n",
        "  if str(cv).isnumeric():\n",
        "    cv = KFold(cv)\n",
        "    gs = GridSearchCV(NNmodel, hparam, scoring=scoring_dic,cv=cv, refit='f1_macro', verbose=v, return_train_score=True)\n",
        "    gs.fit(feat_t, lab_train.to_numpy(dtype=float), verbose=0)\n",
        "    print(gs.best_params_)\n",
        "    print(gs.best_score_)\n",
        "    K.clear_session()\n",
        "    return gs.best_estimator_\n",
        "  elif cv == \"blocked\":\n",
        "    groups= feat_train_df['MLST']\n",
        "    cv = StratifiedGroupKFold(n_splits=4)\n",
        "    gs = GridSearchCV(NNmodel, hparam , scoring=scoring_dic, cv=cv, refit='f1_macro', verbose=v, return_train_score=True)\n",
        "    gs.fit(feat_t, lab_train.to_numpy(dtype=float), verbose=0, groups=groups)\n",
        "    print(gs.best_params_)\n",
        "    print(gs.best_score_)\n",
        "    K.clear_session()\n",
        "    return gs.best_estimator_\n",
        "  else:\n",
        "    print(\"Please input for cv argument 'blocked' or an integer\")\n"
      ],
      "metadata": {
        "id": "OZo9Rql4MdM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the function created (takes longer time)\n",
        "NN_AMX_GY_best_model = NN_hp_tune(hparam, AMX_GY_train_df, AMX_Train_test_dic['labels_train'], drug='AMX', combo='GY', cv=4)"
      ],
      "metadata": {
        "id": "7HIYxC8kexck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9) Use all functions and evaluate every drug in every feature combination!**\n",
        "**NOTE:** Code below is the same as in previous notebook. Hyperparameter tuning of neural networks are very computer resource heavy, due to lack of more RAM (12GB) in the Google Colab environment we have performed the code below already by parts and provided you a CSV file already with the results. If you have access to more RAM in a paid version of Colab or a google cloud environment feel free to run the code below! On the other hand you can also choose to run it without hyperparameter tuning as well."
      ],
      "metadata": {
        "id": "N5lGr0hoDCip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **a) Lets recall the list of drugs we have available and the combination of features we are interested in**"
      ],
      "metadata": {
        "id": "yExXAdaWZL4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check all drugs\n",
        "print(drug_list[9:13])\n",
        "\n",
        "# let's see all combinations we are interested in\n",
        "print(combo_list)\n"
      ],
      "metadata": {
        "id": "51wJM2XUaxtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **b) Create a loop that will go through all our functions using the lists above**"
      ],
      "metadata": {
        "id": "cZWO1rYocRQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in os.listdir(filepath):\n",
        "    if fname.endswith('NN_metrics_df.csv'):\n",
        "        print(\"A csv with stored results for Neural Network has already been created. Please check your Google Drive directory.\")\n",
        "        break\n",
        "else:\n",
        "  # Lets use all our functions this time and save our report into a single data structure\n",
        "  NN_model_metrics = {}\n",
        "\n",
        "  for drug in drug_list:\n",
        "    print(drug)\n",
        "    Test_Train_dic = Split_train_test(drug) # splits each drug df into a dictionary with testing and training data\n",
        "    for combo in combo_list:\n",
        "      # Training each drug_combo features\n",
        "      labels_train = Test_Train_dic[\"labels_train\"]\n",
        "      features_train = combo_feat(Test_Train_dic[\"features_train\"], drug, combo) # create corresponding feature_df for training\n",
        "\n",
        "      NN_combo_model = run_NN(features_train, labels_train, drug=drug, combo=combo, view_epoch=1) # runs NN model using the corresponding training feature df\n",
        "\n",
        "      #Optional: If you want to use the hyperparamter tuning step 8 use this line instead of the previous one:\n",
        "      #NN_combo_model = NN_hp_tune(hparam, features_train, labels_train, v=3, drug=drug, combo=combo) # crossvalidated best model\n",
        "\n",
        "      # Predicting each drug_combo features\n",
        "      features_test = combo_feat(Test_Train_dic[\"features_test\"], drug, combo) # create corresponding feature_df for testing\n",
        "      labels_pred = predict(NN_combo_model, features_test) # generate predictions based on the feature combination tested\n",
        "\n",
        "      # Evaluating our models\n",
        "      labels_test = Test_Train_dic[\"labels_test\"]\n",
        "      report = evaluate(NN_combo_model, features_test, labels_test, labels_pred, cf=False, show_results= False, tunned=False)\n",
        "\n",
        "      #Optional: If you want to use the hyperparamter tuning step 8 use this line instead of the previous one:\n",
        "      #report = evaluate(NN_combo_model, features_test, labels_test, labels_pred, cf=False, show_results= False, tunned=True)\n",
        "\n",
        "      NN_model_metrics[drug+\"_\"+combo] = report\n",
        "\n",
        "      print(report)\n",
        "      K.clear_session()\n",
        "    # convert dictionary into a dataframe\n",
        "  NN_metrics = pd.DataFrame.from_dict(NN_model_metrics, orient='index',columns=[\"Accuracy\", \"R_recall\", \"S_recall\", \"R_precision\", \"S_precision\"]).reset_index()\n",
        "  NN_metrics = NN_metrics.rename(columns = {'index':'Drug_combo'})\n",
        "\n",
        "  # saving our metric results into a CSV file\n",
        "  NN_metrics.to_csv(filepath+\"NN_metrics_df_part4.csv\", index= False)"
      ],
      "metadata": {
        "id": "glSAeIj2DrnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations for making it this far! We have finally finished creating all our Machine Learning Models and saved the results in different dataframes. Our [Last Notebook](https://colab.research.google.com/drive/1MmiXXJZ1QTK3gTwTK7XN0VZnse3NL8Gh?usp=sharing) will now create a graph that will help us pick the best results for each of our antibiotics."
      ],
      "metadata": {
        "id": "RUOmATLxR_mD"
      }
    }
  ]
}